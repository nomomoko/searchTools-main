#!/usr/bin/env python3
"""
æµ‹è¯• AsyncParallelSearchManager çš„å¼‚æ­¥æœç´¢å’Œå»é‡åŠŸèƒ½
ç‹¬ç«‹è¿è¡Œï¼Œé¿å…ç›¸å¯¹å¯¼å…¥é—®é¢˜
"""

import asyncio
import time
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.searchtools.async_parallel_search_manager import AsyncParallelSearchManager


async def test_async_search_and_deduplication():
    """æµ‹è¯•å¼‚æ­¥æœç´¢å’Œå»é‡åŠŸèƒ½"""
    print("ğŸš€ æµ‹è¯• AsyncParallelSearchManager å¼‚æ­¥æœç´¢å’Œå»é‡åŠŸèƒ½")
    print("=" * 60)

    try:
        # åˆ›å»ºæœç´¢ç®¡ç†å™¨å®ä¾‹
        search_manager = AsyncParallelSearchManager()

        # æ˜¾ç¤ºå¯ç”¨çš„æœç´¢æº
        print(f"âœ… å¯ç”¨çš„æœç´¢æºæ•°é‡: {len(search_manager.async_sources)}")
        for source_name in search_manager.async_sources.keys():
            print(f"   - {source_name}")

        if not search_manager.async_sources:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æœç´¢æºï¼Œè¯·æ£€æŸ¥é…ç½®")
            return

        # æµ‹è¯•æŸ¥è¯¢
        test_query = "cancer immunotherapy"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")

        # æ‰§è¡Œå¼‚æ­¥æœç´¢
        print("\nâ³ å¼€å§‹å¼‚æ­¥æœç´¢...")
        start_time = time.time()

        results = await search_manager._async_search_all_sources(test_query)

        search_time = time.time() - start_time
        print(f"âœ… æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.2f}ç§’")

        # æ˜¾ç¤ºæœç´¢ç»“æœç»Ÿè®¡
        print("\nğŸ“Š æœç´¢ç»“æœç»Ÿè®¡:")
        total_results = 0
        for source_name, source_result in results.items():
            if hasattr(source_result, "error") and source_result.error:
                print(f"   {source_name}: âŒ {source_result.error}")
            else:
                result_count = getattr(source_result, "results_count", 0)
                search_time = getattr(source_result, "search_time", 0)
                total_results += result_count
                print(
                    f"   {source_name}: âœ… {result_count} ä¸ªç»“æœ (è€—æ—¶: {search_time:.2f}s)"
                )

        print(f"\n   æ€»è®¡: {total_results} ä¸ªç»“æœ")

        # æ”¶é›†æ‰€æœ‰ç»“æœè¿›è¡Œå»é‡
        print("\nğŸ”„ å¼€å§‹å»é‡å¤„ç†...")

        # è½¬æ¢ä¸º SearchResult å¯¹è±¡åˆ—è¡¨
        from src.searchtools.models import SearchResult

        all_results = []
        for source_name, source_result in results.items():
            if hasattr(source_result, "error") and source_result.error:
                continue

            for result_data in getattr(source_result, "results", []):
                search_result = SearchResult(
                    title=result_data.get("title", ""),
                    authors=result_data.get("authors", ""),
                    journal=result_data.get("journal", ""),
                    year=result_data.get("year", ""),
                    citations=result_data.get("citations", 0),
                    doi=result_data.get("doi", ""),
                    pmid=result_data.get("pmid", ""),
                    pmcid=result_data.get("pmcid", ""),
                    published_date=result_data.get("published_date", ""),
                    url=result_data.get("url", ""),
                    abstract=result_data.get("abstract", ""),
                    source=source_name,
                )
                all_results.append(search_result)

        print(f"   å»é‡å‰ç»“æœæ•°é‡: {len(all_results)}")

        # æ‰§è¡Œå»é‡
        deduplicated_results, duplicate_stats = search_manager.deduplicate_results(
            all_results)

        print(f"   å»é‡åç»“æœæ•°é‡: {len(deduplicated_results)}")
        print("   é‡å¤ç»“æœç»Ÿè®¡:")
        print(f"     - æ€»é‡å¤æ•°: {duplicate_stats['total']}")
        print(f"     - æŒ‰DOIé‡å¤: {duplicate_stats['by_doi']}")
        print(f"     - æŒ‰æ ‡é¢˜é‡å¤: {duplicate_stats['by_title']}")

        # æ˜¾ç¤ºå»é‡åçš„å‰å‡ ä¸ªç»“æœ
        if deduplicated_results:
            print("\nğŸ“‹ å»é‡åçš„å‰3ä¸ªç»“æœ:")
            for i, result in enumerate(deduplicated_results[:3]):
                print(f"   {i + 1}. {result.title}")
                print(f"      ä½œè€…: {result.authors}")
                print(f"      æœŸåˆŠ: {result.journal}")
                print(f"      å¹´ä»½: {result.year}")
                print(f"      DOI: {result.doi}")
                print(f"      æ¥æº: {result.source}")
                print()

        print("âœ… æµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    try:
        asyncio.run(test_async_search_and_deduplication())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
