from dotenv import load_dotenv
load_dotenv()

import sys
import os
# æ·»åŠ  src è·¯å¾„åˆ°æœç´¢è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))
#!/usr/bin/env python3
"""
SearchTools ä¸»ç¨‹åº
æä¾›å¼‚æ­¥æœç´¢å’Œå»é‡åŠŸèƒ½ï¼Œé€‚åˆ FastAPI åç«¯è°ƒç”¨
"""

import asyncio
import json

from searchtools.async_parallel_search_manager import \
    AsyncParallelSearchManager 
from searchtools.models import SearchResult


async def search_and_deduplicate(query: str = "diabetes"):
    """
    æ‰§è¡Œå¼‚æ­¥æœç´¢å’Œå»é‡

    Args:
        query (str): æœç´¢æŸ¥è¯¢è¯ï¼Œé»˜è®¤ä½¿ç”¨ "diabetes"

    Returns:
        tuple: (å»é‡åçš„ç»“æœåˆ—è¡¨, é‡å¤ç»Ÿè®¡ä¿¡æ¯)
    """
    # åˆ›å»ºæœç´¢ç®¡ç†å™¨
    search_manager = AsyncParallelSearchManager()

    # æ‰§è¡Œå¼‚æ­¥æœç´¢
    results = await search_manager._async_search_all_sources(query)

    # æ”¶é›†æ‰€æœ‰ç»“æœ
    all_results = []
    for source_name, source_result in results.items():
        if hasattr(source_result, "error") and source_result.error:
            continue

        for result_data in getattr(source_result, "results", []):
            search_result = SearchResult(
                title=result_data.get("title", ""),
                authors=result_data.get("authors", ""),
                journal=result_data.get("journal", ""),
                year=result_data.get("year", ""),
                citations=result_data.get("citations", 0),
                doi=result_data.get("doi", ""),
                pmid=result_data.get("pmid", ""),
                pmcid=result_data.get("pmcid", ""),
                published_date=result_data.get("published_date", ""),
                url=result_data.get("url", ""),
                abstract=result_data.get("abstract", ""),
                source=source_name,
            )
            all_results.append(search_result)

    # æ‰§è¡Œå»é‡
    deduplicated_results, duplicate_stats = search_manager.deduplicate_results(
        all_results)

    return deduplicated_results, duplicate_stats


async def main():
    """ä¸»å‡½æ•° - æµ‹è¯•æœç´¢å’Œå»é‡åŠŸèƒ½"""
    print("ğŸ” å¼€å§‹æœç´¢: diabetes")

    # æ‰§è¡Œæœç´¢å’Œå»é‡
    results, stats = await search_and_deduplicate("breast cancer")

    # è¾“å‡ºç»“æœç»Ÿè®¡
    print(f"ğŸ“Š æœç´¢ç»“æœ: {len(results)} ä¸ªå»é‡åçš„ç»“æœ")
    print(f"ğŸ”„ é‡å¤ç»Ÿè®¡: {stats}")

    # è¾“å‡ºå»é‡åçš„åŸå§‹ç»“æœï¼ˆé€‚åˆ FastAPI è¿”å›ï¼‰
    print("\nğŸ“‹ å»é‡åçš„ç»“æœ:")
    for result in results:
        print(
            json.dumps(
                {
                    "title": result.title,
                    "authors": result.authors,
                    "journal": result.journal,
                    "year": result.year,
                    "citations": result.citations,
                    "doi": result.doi,
                    "pmid": result.pmid,
                    "pmcid": result.pmcid,
                    "published_date": result.published_date,
                    "url": result.url,
                    "abstract": result.abstract,
                    "source": result.source,
                },
                ensure_ascii=False,
                indent=2,
            ))


if __name__ == "__main__":
    asyncio.run(main())
