# ðŸš€ éƒ¨ç½²å’Œè¿è¡ŒæŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†SearchToolsé¡¹ç›®çš„éƒ¨ç½²ã€è¿è¡Œå’Œç»´æŠ¤æ–¹æ³•ï¼Œé€‚ç”¨äºŽå¼€å‘ã€æµ‹è¯•å’Œç”Ÿäº§çŽ¯å¢ƒã€‚

## ðŸ“‹ ç³»ç»Ÿè¦æ±‚

### æœ€ä½Žè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python**: 3.10+
- **å†…å­˜**: 4GB RAM
- **å­˜å‚¨**: 1GB å¯ç”¨ç©ºé—´
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿žæŽ¥

### æŽ¨èé…ç½®
- **å†…å­˜**: 8GB+ RAM
- **CPU**: 4æ ¸å¿ƒ+
- **ç½‘ç»œ**: 100Mbps+ å¸¦å®½
- **å­˜å‚¨**: SSDç¡¬ç›˜

## ðŸ› ï¸ å®‰è£…éƒ¨ç½²

### 1. çŽ¯å¢ƒå‡†å¤‡

#### PythonçŽ¯å¢ƒ
```bash
# æ£€æŸ¥Pythonç‰ˆæœ¬
python --version  # åº”è¯¥ >= 3.10

# åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒï¼ˆæŽ¨èï¼‰
python -m venv searchtools_env

# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
# Windows:
searchtools_env\Scripts\activate
# Linux/Mac:
source searchtools_env/bin/activate
```

#### é¡¹ç›®ä¸‹è½½
```bash
# æ–¹å¼1: Gitå…‹éš†
git clone https://github.com/nomomoko/searchTools-main.git
cd searchTools-main

# æ–¹å¼2: ä¸‹è½½ZIP
# ä»ŽGitHubä¸‹è½½ZIPæ–‡ä»¶å¹¶è§£åŽ‹
```

### 2. ä¾èµ–å®‰è£…

#### åŸºç¡€ä¾èµ–
```bash
# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -e .

# å®‰è£…é«˜çº§ç®—æ³•ä¾èµ–
pip install numpy

# éªŒè¯å®‰è£…
python -c "import searchtools; print('å®‰è£…æˆåŠŸ')"
```

#### å¯é€‰ä¾èµ–
```bash
# æ€§èƒ½ç›‘æŽ§
pip install psutil

# å¼€å‘å·¥å…·
pip install pytest black flake8

# ç”Ÿäº§éƒ¨ç½²
pip install gunicorn
```

### 3. é…ç½®è®¾ç½®

#### çŽ¯å¢ƒå˜é‡é…ç½®
```bash
# åˆ›å»º .env æ–‡ä»¶
cat > .env << EOF
# APIå¯†é’¥
SEMANTIC_SCHOLAR_API_KEY=your_api_key_here

# æœç´¢é…ç½®
SEARCH_TOOLS_MAX_CONCURRENT_REQUESTS=5
SEARCH_TOOLS_DEFAULT_TIMEOUT=30.0

# é‡æŽ’åºé…ç½®
SEARCH_TOOLS_ENABLE_RERANK=true
SEARCH_TOOLS_ALGORITHM_MODE=hybrid
SEARCH_TOOLS_ENABLE_CACHING=true
SEARCH_TOOLS_CACHE_SIZE=1000

# æƒé‡é…ç½®
SEARCH_TOOLS_RERANK_RELEVANCE_WEIGHT=0.40
SEARCH_TOOLS_RERANK_AUTHORITY_WEIGHT=0.30
SEARCH_TOOLS_RERANK_RECENCY_WEIGHT=0.20
SEARCH_TOOLS_RERANK_QUALITY_WEIGHT=0.10

# æ—¥å¿—é…ç½®
SEARCH_TOOLS_LOG_LEVEL=INFO
SEARCH_TOOLS_LOG_TO_FILE=false
EOF
```

#### ä»£ç†é…ç½®ï¼ˆå¯é€‰ï¼‰
```bash
# å¦‚æžœéœ€è¦ä»£ç†è®¿é—®
export HTTP_PROXY=http://proxy.example.com:8080
export HTTPS_PROXY=http://proxy.example.com:8080
```

## ðŸŽ¯ è¿è¡Œæ–¹å¼

### 1. å¼€å‘æ¨¡å¼

#### ç›´æŽ¥è¿è¡Œ
```bash
# å¯åŠ¨WebæœåŠ¡
python app.py

# è®¿é—®åœ°å€: http://localhost:8000
```

#### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export SEARCH_TOOLS_LOG_LEVEL=DEBUG
python app.py
```

### 2. ç”Ÿäº§æ¨¡å¼

#### ä½¿ç”¨uvicorn
```bash
# å•è¿›ç¨‹
uvicorn app:app --host 0.0.0.0 --port 8000

# å¤šè¿›ç¨‹ï¼ˆæŽ¨èï¼‰
uvicorn app:app --host 0.0.0.0 --port 8000 --workers 4
```

#### ä½¿ç”¨gunicorn
```bash
# å®‰è£…gunicorn
pip install gunicorn

# å¯åŠ¨æœåŠ¡
gunicorn app:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### 3. å®¹å™¨åŒ–éƒ¨ç½²

#### Dockerfile
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . .

# å®‰è£…Pythonä¾èµ–
RUN pip install -e . && pip install numpy gunicorn

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["gunicorn", "app:app", "-w", "4", "-k", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8000"]
```

#### Docker Compose
```yaml
version: '3.8'

services:
  searchtools:
    build: .
    ports:
      - "8000:8000"
    environment:
      - SEARCH_TOOLS_ENABLE_RERANK=true
      - SEARCH_TOOLS_CACHE_SIZE=2000
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - searchtools
    restart: unless-stopped
```

## ðŸ”§ é…ç½®ä¼˜åŒ–

### æ€§èƒ½è°ƒä¼˜

#### å†…å­˜ä¼˜åŒ–
```bash
# è°ƒæ•´ç¼“å­˜å¤§å°
export SEARCH_TOOLS_CACHE_SIZE=2000  # æ ¹æ®å†…å­˜è°ƒæ•´

# å¯ç”¨ç¼“å­˜
export SEARCH_TOOLS_ENABLE_CACHING=true
```

#### å¹¶å‘ä¼˜åŒ–
```bash
# è°ƒæ•´å¹¶å‘è¯·æ±‚æ•°
export SEARCH_TOOLS_MAX_CONCURRENT_REQUESTS=8  # æ ¹æ®ç½‘ç»œè°ƒæ•´

# è°ƒæ•´è¶…æ—¶æ—¶é—´
export SEARCH_TOOLS_DEFAULT_TIMEOUT=45.0
```

#### ç®—æ³•ä¼˜åŒ–
```bash
# é€‰æ‹©ç®—æ³•æ¨¡å¼
export SEARCH_TOOLS_ALGORITHM_MODE=traditional  # æœ€å¿«
export SEARCH_TOOLS_ALGORITHM_MODE=hybrid       # å¹³è¡¡ï¼ˆæŽ¨èï¼‰
export SEARCH_TOOLS_ALGORITHM_MODE=ml_only      # æœ€å‡†ç¡®
```

### è´Ÿè½½å‡è¡¡é…ç½®

#### Nginxé…ç½®
```nginx
upstream searchtools {
    server 127.0.0.1:8001;
    server 127.0.0.1:8002;
    server 127.0.0.1:8003;
    server 127.0.0.1:8004;
}

server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://searchtools;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_connect_timeout 60s;
        proxy_read_timeout 300s;
    }
}
```

## ðŸ“Š ç›‘æŽ§å’Œç»´æŠ¤

### å¥åº·æ£€æŸ¥
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥APIåŠŸèƒ½
curl -X POST "http://localhost:8000/search" \
     -H "Content-Type: application/json" \
     -d '{"query": "test", "max_results": 1}'
```

### æ—¥å¿—ç®¡ç†
```bash
# å¯ç”¨æ–‡ä»¶æ—¥å¿—
export SEARCH_TOOLS_LOG_TO_FILE=true
export SEARCH_TOOLS_LOG_FILE_PATH=/var/log/searchtools.log

# æ—¥å¿—è½®è½¬ï¼ˆlogrotateé…ç½®ï¼‰
cat > /etc/logrotate.d/searchtools << EOF
/var/log/searchtools.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 644 www-data www-data
}
EOF
```

### æ€§èƒ½ç›‘æŽ§
```python
# ç›‘æŽ§è„šæœ¬ç¤ºä¾‹
import requests
import time
import psutil

def monitor_performance():
    # APIå“åº”æ—¶é—´
    start = time.time()
    response = requests.post('http://localhost:8000/search', 
                           json={'query': 'test', 'max_results': 5})
    api_time = time.time() - start
    
    # ç³»ç»Ÿèµ„æº
    cpu_percent = psutil.cpu_percent()
    memory_percent = psutil.virtual_memory().percent
    
    print(f"APIå“åº”æ—¶é—´: {api_time:.2f}s")
    print(f"CPUä½¿ç”¨çŽ‡: {cpu_percent}%")
    print(f"å†…å­˜ä½¿ç”¨çŽ‡: {memory_percent}%")

if __name__ == "__main__":
    monitor_performance()
```

## ðŸš¨ æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜

#### 1. ä¾èµ–å®‰è£…å¤±è´¥
```bash
# å‡çº§pip
pip install --upgrade pip

# æ¸…ç†ç¼“å­˜
pip cache purge

# é‡æ–°å®‰è£…
pip install -e . --force-reinstall
```

#### 2. å†…å­˜ä¸è¶³
```bash
# å‡å°‘ç¼“å­˜å¤§å°
export SEARCH_TOOLS_CACHE_SIZE=500

# ä½¿ç”¨traditionalæ¨¡å¼
export SEARCH_TOOLS_ALGORITHM_MODE=traditional
```

#### 3. ç½‘ç»œè¶…æ—¶
```bash
# å¢žåŠ è¶…æ—¶æ—¶é—´
export SEARCH_TOOLS_DEFAULT_TIMEOUT=60.0

# å‡å°‘å¹¶å‘æ•°
export SEARCH_TOOLS_MAX_CONCURRENT_REQUESTS=3
```

#### 4. APIå¯†é’¥é—®é¢˜
```bash
# æ£€æŸ¥å¯†é’¥è®¾ç½®
echo $SEMANTIC_SCHOLAR_API_KEY

# æµ‹è¯•APIè®¿é—®
curl "https://api.semanticscholar.org/graph/v1/paper/search?query=test&limit=1"
```

### è°ƒè¯•æŠ€å·§
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export SEARCH_TOOLS_LOG_LEVEL=DEBUG

# è¿è¡Œæµ‹è¯•
python test_rerank.py

# æ£€æŸ¥é…ç½®
python -c "from searchtools.search_config import get_config; print(get_config())"
```

## ðŸ”„ æ›´æ–°å‡çº§

### ä»£ç æ›´æ–°
```bash
# æ‹‰å–æœ€æ–°ä»£ç 
git pull origin main

# é‡æ–°å®‰è£…ä¾èµ–
pip install -e . --upgrade

# é‡å¯æœåŠ¡
# æ ¹æ®éƒ¨ç½²æ–¹å¼é‡å¯
```

### æ•°æ®è¿ç§»
```bash
# æ¸…ç†ç¼“å­˜ï¼ˆå¦‚æžœéœ€è¦ï¼‰
python -c "
from searchtools.rerank_engine import get_rerank_engine
engine = get_rerank_engine()
engine.clear_cache()
print('ç¼“å­˜å·²æ¸…ç†')
"
```

---

*SearchTools éƒ¨ç½²æŒ‡å— - è®©éƒ¨ç½²å˜å¾—ç®€å•å¯é ï¼*
