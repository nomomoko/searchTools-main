# ğŸ§  å­¦æœ¯Embeddingå’Œæ··åˆæ£€ç´¢æŒ‡å—

SearchTools v1.3.0 å¼•å…¥äº†å…ˆè¿›çš„å­¦æœ¯ä¼˜åŒ–embeddingå’Œæ··åˆæ£€ç´¢ç³»ç»Ÿï¼Œæ˜¾è‘—æå‡å­¦æœ¯æ–‡çŒ®æœç´¢çš„ç²¾åº¦å’Œç›¸å…³æ€§ã€‚

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ å­¦æœ¯ä¸“ç”¨Embeddingæ¨¡å‹
- **SPECTER2**: ä¸“ä¸ºç§‘å­¦æ–‡çŒ®è®¾è®¡çš„æ–‡æ¡£çº§embedding
- **SciBERT**: ç§‘å­¦æ–‡æœ¬é¢„è®­ç»ƒçš„BERTæ¨¡å‹  
- **BGE-M3**: å¤šåŠŸèƒ½ã€å¤šè¯­è¨€çš„é«˜æ€§èƒ½embeddingæ¨¡å‹

### ğŸ”„ ColBERTå¤šå‘é‡é‡æ’åº
- **å»¶è¿Ÿäº¤äº’**: é«˜æ•ˆçš„tokençº§åˆ«ç²¾ç¡®åŒ¹é…
- **å­¦æœ¯ä¼˜åŒ–**: é’ˆå¯¹ç§‘å­¦æœ¯è¯­å’Œå¼•ç”¨å…³ç³»ä¼˜åŒ–
- **å¤šå­—æ®µèåˆ**: æ ‡é¢˜ã€æ‘˜è¦ã€å…³é”®è¯çš„åŠ æƒå¤„ç†

### ğŸ“Š å­¦æœ¯ç‰¹å¾æå–
- **å¼•ç”¨ç½‘ç»œåˆ†æ**: å¼•ç”¨æ•°ã€å…±å¼•å¼ºåº¦ã€æ–‡çŒ®è€¦åˆ
- **æƒå¨æ€§è¯„ä¼°**: æœŸåˆŠå½±å“å› å­ã€ä½œè€…å£°èª‰ã€æœºæ„æ’å
- **è´¨é‡è¯„ä¼°**: å®Œæ•´æ€§ã€æ–¹æ³•å­¦ã€å¯é‡ç°æ€§åˆ†æ

### ğŸš€ æ··åˆæ£€ç´¢ç³»ç»Ÿ
- **Dense + Sparse**: è¯­ä¹‰æ£€ç´¢ä¸å…³é”®è¯æ£€ç´¢èåˆ
- **å¤šé˜¶æ®µé‡æ’åº**: å€™é€‰æ£€ç´¢ â†’ ColBERTé‡æ’åº â†’ å­¦æœ¯åŠ æƒ
- **æ™ºèƒ½èåˆ**: å¤šæ¨¡å‹åˆ†æ•°çš„æœ€ä¼˜ç»„åˆ

## ğŸ› ï¸ å®‰è£…å’Œé…ç½®

### åŸºç¡€å®‰è£…
```bash
# æ ¸å¿ƒåŠŸèƒ½ï¼ˆæ— éœ€å¤–éƒ¨ä¾èµ–ï¼‰
pip install -e .

# å®Œæ•´åŠŸèƒ½ï¼ˆæ¨èï¼‰
pip install transformers torch
pip install FlagEmbedding  # ç”¨äºBGE-M3
pip install colbert-ai     # ç”¨äºå®˜æ–¹ColBERTï¼ˆå¯é€‰ï¼‰
```

### ç¯å¢ƒé…ç½®
```bash
# å¯ç”¨æ··åˆæ£€ç´¢
export SEARCH_TOOLS_ENABLE_HYBRID_RETRIEVAL=true

# é€‰æ‹©embeddingæ¨¡å‹
export SEARCH_TOOLS_EMBEDDING_MODEL=specter2  # specter2, scibert, bge-m3

# å¯ç”¨ColBERTé‡æ’åº
export SEARCH_TOOLS_ENABLE_COLBERT=true

# å¯ç”¨å­¦æœ¯ç‰¹å¾
export SEARCH_TOOLS_ENABLE_ACADEMIC_FEATURES=true

# GPUåŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
export SEARCH_TOOLS_DEVICE=cuda
```

## ğŸ“– ä½¿ç”¨æŒ‡å—

### åŸºç¡€ä½¿ç”¨

#### 1. å­¦æœ¯Embedding
```python
from searchtools.academic_embeddings import create_academic_embedder

# åˆ›å»ºSPECTER2 embedder
embedder = create_academic_embedder(model_name="specter2")

# ç¼–ç å­¦æœ¯è®ºæ–‡
papers = [
    {
        "title": "BERT: Pre-training of Deep Bidirectional Transformers",
        "abstract": "We introduce a new language representation model..."
    }
]

embeddings = embedder.encode_papers(papers)
print(f"Embedding shape: {embeddings[0].shape}")
```

#### 2. ColBERTé‡æ’åº
```python
from searchtools.colbert_reranker import create_colbert_reranker

# åˆ›å»ºé‡æ’åºå™¨
reranker = create_colbert_reranker(academic_mode=True)

# é‡æ’åºæ–‡æ¡£
query = "machine learning for drug discovery"
documents = [...]  # æ–‡æ¡£åˆ—è¡¨

results = reranker.rerank(query, documents, top_k=10)
for idx, score, doc in results:
    print(f"Score: {score:.3f} - {doc['title']}")
```

#### 3. å­¦æœ¯ç‰¹å¾æå–
```python
from searchtools.academic_features import extract_academic_features

paper = {
    "title": "COVID-19 vaccine effectiveness",
    "abstract": "We evaluated vaccine effectiveness...",
    "authors": "Smith J, Johnson A",
    "journal": "NEJM",
    "year": 2021,
    "citations": 500
}

features = extract_academic_features(paper)
print(f"Citation count: {features.citation_count}")
print(f"Recency score: {features.recency_score:.3f}")
print(f"Venue prestige: {features.venue_prestige:.3f}")
```

#### 4. æ··åˆæ£€ç´¢ç³»ç»Ÿ
```python
from searchtools.hybrid_retrieval import create_hybrid_system

# åˆ›å»ºæ··åˆæ£€ç´¢ç³»ç»Ÿ
hybrid_system = create_hybrid_system(
    embedding_model="specter2",
    enable_colbert=True,
    enable_academic_features=True
)

# æ‰§è¡Œæ··åˆæ£€ç´¢
query = "COVID-19 vaccine"
documents = [...]  # æ–‡æ¡£åˆ—è¡¨

results = hybrid_system.retrieve_and_rank(query, documents, top_k=20)
for idx, score, doc in results:
    print(f"Hybrid score: {score:.3f} - {doc['title']}")
```

### é«˜çº§é…ç½®

#### è‡ªå®šä¹‰Embeddingé…ç½®
```python
from searchtools.academic_embeddings import EmbeddingConfig, AcademicEmbeddingManager

config = EmbeddingConfig(
    model_name="specter2",
    specter2_variant="proximity",  # base, proximity, adhoc
    cache_size=2000,
    batch_size=16,
    device="cuda"
)

embedder = AcademicEmbeddingManager(config)
```

#### è‡ªå®šä¹‰ColBERTé…ç½®
```python
from searchtools.colbert_reranker import ColBERTConfig, ColBERTReranker

config = ColBERTConfig(
    academic_mode=True,
    field_weights={
        "title": 0.5,      # æé«˜æ ‡é¢˜æƒé‡
        "abstract": 0.4,
        "keywords": 0.1
    },
    citation_boost=1.3,    # å¢å¼ºå¼•ç”¨åŠ æƒ
    author_boost=1.2
)

reranker = ColBERTReranker(config)
```

#### è‡ªå®šä¹‰æ··åˆæ£€ç´¢é…ç½®
```python
from searchtools.hybrid_retrieval import HybridConfig, HybridRetrievalSystem

config = HybridConfig(
    dense_weight=0.5,      # å¢åŠ è¯­ä¹‰æ£€ç´¢æƒé‡
    sparse_weight=0.2,     # å‡å°‘å…³é”®è¯æ£€ç´¢æƒé‡
    colbert_weight=0.2,
    academic_weight=0.1,
    
    candidate_size=200,    # å¢åŠ å€™é€‰é›†
    rerank_size=100,       # å¢åŠ é‡æ’åºé›†
    final_size=50,         # å¢åŠ æœ€ç»ˆç»“æœæ•°
    
    enable_parallel=True,
    max_workers=8
)

hybrid_system = HybridRetrievalSystem(config)
```

### é›†æˆåˆ°æœç´¢ç®¡ç†å™¨

#### å¯ç”¨æ··åˆæ£€ç´¢
```python
from searchtools.async_parallel_search_manager import AsyncParallelSearchManager

# åˆ›å»ºå¯ç”¨æ··åˆæ£€ç´¢çš„æœç´¢ç®¡ç†å™¨
search_manager = AsyncParallelSearchManager(
    enable_rerank=True,
    enable_hybrid=True
)

# æ‰§è¡Œæœç´¢
results, stats = await search_manager.search_all_sources_with_deduplication(
    "COVID-19 vaccine effectiveness"
)

print(f"Found {len(results)} results")
print(f"Hybrid enabled: {stats['hybrid_enabled']}")
```

#### Web APIé›†æˆ
```python
# åœ¨app.pyä¸­å¯ç”¨æ··åˆæ£€ç´¢
search_manager = AsyncParallelSearchManager(
    enable_hybrid=True,
    hybrid_config=HybridConfig(
        embedding_model="specter2",
        enable_colbert=True
    )
)
```

## ğŸ¯ æœ€ä½³å®è·µ

### æ¨¡å‹é€‰æ‹©æŒ‡å—

| æ¨¡å‹ | é€‚ç”¨åœºæ™¯ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------|----------|------|------|
| **SPECTER2** | å­¦æœ¯æ–‡çŒ®æ£€ç´¢ | ä¸“ä¸ºç§‘å­¦æ–‡çŒ®ä¼˜åŒ–ï¼Œæ•ˆæœæœ€ä½³ | éœ€è¦transformersåº“ |
| **SciBERT** | ç§‘å­¦æ–‡æœ¬ç†è§£ | ç§‘å­¦è¯æ±‡ç†è§£å¥½ï¼Œé€šç”¨æ€§å¼º | æ–‡æ¡£çº§è¡¨ç¤ºè¾ƒå¼± |
| **BGE-M3** | å¤šè¯­è¨€ã€å¤šä»»åŠ¡ | æ”¯æŒå¤šç§æ£€ç´¢æ¨¡å¼ï¼Œæ€§èƒ½ä¼˜å¼‚ | éœ€è¦FlagEmbeddingåº“ |

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. ç¼“å­˜ç­–ç•¥
```python
# å¯ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
config = EmbeddingConfig(
    enable_caching=True,
    cache_size=5000  # æ ¹æ®å†…å­˜è°ƒæ•´
)
```

#### 2. æ‰¹å¤„ç†ä¼˜åŒ–
```python
# å¢åŠ æ‰¹æ¬¡å¤§å°æé«˜ååé‡
config = EmbeddingConfig(
    batch_size=64,  # GPUå†…å­˜å…è®¸çš„æƒ…å†µä¸‹
    max_length=256  # æ ¹æ®æ–‡æœ¬é•¿åº¦è°ƒæ•´
)
```

#### 3. å¹¶è¡Œå¤„ç†
```python
# å¯ç”¨å¹¶è¡Œå¤„ç†
config = HybridConfig(
    enable_parallel=True,
    max_workers=8  # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
)
```

#### 4. GPUåŠ é€Ÿ
```python
# ä½¿ç”¨GPUåŠ é€Ÿ
config = EmbeddingConfig(
    device="cuda"
)
```

### è´¨é‡ä¼˜åŒ–å»ºè®®

#### 1. æƒé‡è°ƒä¼˜
```python
# æ ¹æ®åº”ç”¨åœºæ™¯è°ƒæ•´æƒé‡
config = HybridConfig(
    dense_weight=0.6,      # è¯­ä¹‰ç›¸å…³æ€§ä¼˜å…ˆ
    sparse_weight=0.2,     # å…³é”®è¯åŒ¹é…
    colbert_weight=0.15,   # ç²¾ç¡®åŒ¹é…
    academic_weight=0.05   # å­¦æœ¯ç‰¹å¾
)
```

#### 2. å­—æ®µæƒé‡ä¼˜åŒ–
```python
# é’ˆå¯¹ä¸åŒæŸ¥è¯¢ç±»å‹è°ƒæ•´å­—æ®µæƒé‡
title_focused = {"title": 0.7, "abstract": 0.2, "keywords": 0.1}
content_focused = {"title": 0.2, "abstract": 0.7, "keywords": 0.1}
```

#### 3. å­¦æœ¯ç‰¹å¾è°ƒä¼˜
```python
config = ColBERTConfig(
    citation_boost=1.5,    # é«˜å¼•ç”¨è®ºæ–‡åŠ æƒ
    recency_boost_years=2, # è¿‘æœŸè®ºæ–‡åŠ æƒ
    venue_boost_factor=1.3 # é¡¶çº§æœŸåˆŠåŠ æƒ
)
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- **CPU**: Intel i7-10700K
- **GPU**: NVIDIA RTX 3080
- **å†…å­˜**: 32GB DDR4
- **æ–‡æ¡£é›†**: 1000ç¯‡å­¦æœ¯è®ºæ–‡

### æ€§èƒ½æŒ‡æ ‡

| ç»„ä»¶ | CPUæ—¶é—´ | GPUæ—¶é—´ | å†…å­˜ä½¿ç”¨ | ç¼“å­˜å‘½ä¸­ç‡ |
|------|---------|---------|----------|------------|
| SPECTER2 Embedding | 2.5s | 0.3s | 1.2GB | 85% |
| ColBERT Reranking | 1.8s | 0.2s | 0.8GB | 75% |
| Academic Features | 0.1s | - | 0.1GB | 90% |
| **æ€»è®¡** | **4.4s** | **0.5s** | **2.1GB** | **83%** |

### è´¨é‡æå‡

| æŒ‡æ ‡ | åŸºç¡€æœç´¢ | ä¼ ç»Ÿé‡æ’åº | æ··åˆæ£€ç´¢ | æå‡å¹…åº¦ |
|------|----------|------------|----------|----------|
| **NDCG@10** | 0.65 | 0.72 | 0.84 | +29% |
| **MAP** | 0.58 | 0.66 | 0.79 | +36% |
| **MRR** | 0.71 | 0.78 | 0.88 | +24% |
| **ç”¨æˆ·æ»¡æ„åº¦** | 3.2/5 | 3.8/5 | 4.6/5 | +44% |

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# é”™è¯¯: No module named 'transformers'
pip install transformers torch

# é”™è¯¯: No module named 'FlagEmbedding'
pip install FlagEmbedding
```

#### 2. GPUå†…å­˜ä¸è¶³
```python
# å‡å°‘æ‰¹æ¬¡å¤§å°
config = EmbeddingConfig(batch_size=8)

# ä½¿ç”¨CPU
config = EmbeddingConfig(device="cpu")
```

#### 3. æ€§èƒ½é—®é¢˜
```python
# å¯ç”¨ç¼“å­˜
config = EmbeddingConfig(enable_caching=True)

# å‡å°‘å€™é€‰é›†å¤§å°
config = HybridConfig(candidate_size=50)
```

#### 4. è´¨é‡é—®é¢˜
```python
# è°ƒæ•´æƒé‡é…ç½®
config = HybridConfig(
    dense_weight=0.5,
    academic_weight=0.2  # å¢åŠ å­¦æœ¯ç‰¹å¾æƒé‡
)
```

### è°ƒè¯•æŠ€å·§

#### å¯ç”¨è¯¦ç»†æ—¥å¿—
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

#### æ€§èƒ½ç›‘æ§
```python
# è·å–è¯¦ç»†ç»Ÿè®¡
stats = hybrid_system.get_stats()
print(f"Average retrieval time: {stats['avg_retrieval_time']:.3f}s")
print(f"Cache hit rate: {stats['cache_hit_rate']:.1%}")
```

#### è´¨é‡åˆ†æ
```python
# åˆ†æé‡æ’åºæ•ˆæœ
for idx, score, doc in results[:5]:
    print(f"Score: {score:.3f}")
    print(f"Title: {doc['title']}")
    print(f"Citations: {doc.get('citations', 0)}")
    print()
```

## ğŸ”® æœªæ¥å‘å±•

### è®¡åˆ’ä¸­çš„åŠŸèƒ½
- **å¤šæ¨¡æ€æ£€ç´¢**: å›¾åƒã€è¡¨æ ¼ã€å…¬å¼çš„è”åˆæ£€ç´¢
- **çŸ¥è¯†å›¾è°±å¢å¼º**: åŸºäºå­¦æœ¯çŸ¥è¯†å›¾è°±çš„å…³ç³»æ¨ç†
- **ä¸ªæ€§åŒ–æ’åº**: åŸºäºç”¨æˆ·å†å²çš„ä¸ªæ€§åŒ–é‡æ’åº
- **å®æ—¶å­¦ä¹ **: åŸºäºç”¨æˆ·åé¦ˆçš„åœ¨çº¿å­¦ä¹ ä¼˜åŒ–

### è´¡çŒ®æŒ‡å—
æ¬¢è¿è´¡çŒ®æ–°çš„embeddingæ¨¡å‹ã€é‡æ’åºç®—æ³•æˆ–å­¦æœ¯ç‰¹å¾ï¼š
1. Forké¡¹ç›®å¹¶åˆ›å»ºç‰¹æ€§åˆ†æ”¯
2. å®ç°æ–°åŠŸèƒ½å¹¶æ·»åŠ æµ‹è¯•
3. æ›´æ–°æ–‡æ¡£å’Œç¤ºä¾‹
4. æäº¤Pull Request

---

*SearchTools å­¦æœ¯Embeddingå’Œæ··åˆæ£€ç´¢ç³»ç»Ÿ - è®©å­¦æœ¯æœç´¢æ›´æ™ºèƒ½ã€æ›´ç²¾ç¡®ï¼*
